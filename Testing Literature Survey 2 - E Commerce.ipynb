{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Literature Survey 2 - E Commerce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we run our project using a dataset of Flipkart Product Reviews acquired through Kaggle. We found this dataset to be very similar to the one used in our literature survey. By testing our models, we can draw a comparison between our performance and that of Naive Bayes reported in the research papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset and Libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Abhinav\n",
      "[nltk_data]     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Abhinav\n",
      "[nltk_data]     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import os\n",
    "\n",
    "import spacy \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import folium\n",
    "from itertools import cycle, islice\n",
    "from pandas import options\n",
    "import warnings\n",
    "import pickle\n",
    "import nltk\n",
    "from matplotlib.pyplot import figure\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "\n",
    "from  wordcloud import WordCloud\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_SET = './datasets/aclimdb.csv'\n",
    "df =pd.read_csv('ECommerceDataset.csv',encoding='latin1', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(lambda x: x if isinstance(x, str)==True else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment = pd.to_numeric(df.sentiment, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment = df.sentiment.apply(lambda x: 1 if x>=3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['sentiment'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['review'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.index > 150000].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it's really worth every single penny. it works...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i bought crompton ozone 75 desert air cooler i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great packaging by seller. as this was the mos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>delivery was delayed by two days except this e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a good cooler by crompton. the height of the c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  it's really worth every single penny. it works...          1\n",
       "1  i bought crompton ozone 75 desert air cooler i...          1\n",
       "2  great packaging by seller. as this was the mos...          1\n",
       "3  delivery was delayed by two days except this e...          1\n",
       "4  a good cooler by crompton. the height of the c...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lowercasing all the words in the review\n",
    "df['review']=df['review'].apply(lambda x: x.lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contraction to expansion : \n",
    "#converting the words in their contracted form to their extracted form eg. he'll to he will\n",
    "#using the cont_to_exp() and a dictionary:{key: contractions,value:expansion}\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\"aren't\": \"are not\",\"can't\": \"cannot\",\"can't've\": \"cannot have\",\"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\"hasn't\": \"has not\",\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\"he'd've\": \"he would have\",\"he'll\": \"he will\",\"he'll've\": \"he will have\",\"he's\": \"he is\",\"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"how's\": \"how does\",\n",
    "\"i'd\": \"i would\",\"i'd've\": \"i would have\",\"i'll\": \"i will\",\"i'll've\": \"i will have\",\"i'm\": \"i am\",\"i've\": \"i have\",\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\"it'll've\": \"it will have\",\"it's\": \"it is\",\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\"she'd've\": \"she would have\",\"she'll\": \"she will\",\"she'll've\": \"she will have\",\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\"shouldn't\": \"should not\",\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\"so's\": \"so is\",\n",
    "\"that'd\": \"that would\",\"that'd've\": \"that would have\",\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\"there'd've\": \"there would have\",\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\"they're\": \"they are\",\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\"wasn't\": \"was not\",\n",
    "\" u \": \" you \",\" ur \": \" your \",\" n \": \" and \",\n",
    "\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \n",
    "\"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \n",
    "\"how'd\": \"how did\", \"how'd'y\": \"how do you\", \n",
    "\"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "def cont_to_exp(x):\n",
    "    if type(x) is str:\n",
    "        for key in contractions:\n",
    "            value = contractions[key]\n",
    "            x = x.replace(key,value)\n",
    "        return x\n",
    "    else : \n",
    "        return x\n",
    "df['review'] = df['review'].apply(lambda x:cont_to_exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the urls from the reviews\n",
    "df['review']=df['review'].apply(lambda x: re.sub(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?','',x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopword removal : Stopwords are the words that appear quite frequently in a sentence and do not have a significant contribution to the meaning of the sentence. Therefore they can be removed.\n",
    "df['review'] = df['review'].apply(lambda x:\" \".join([t for t in x.split() if t not in STOP_WORDS ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of special characters from the reviews\n",
    "df['review']=df['review'].apply(lambda x:re.sub(r'[^0-9a-zA-Z *]','',x))\n",
    "df['review']=df['review'].apply(lambda x:re.sub(r'[^a-zA-z0-9\\s]','',x))\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removal of mulitple spaces between the words in the review\n",
    "df[\"review\"]=df[\"review\"].apply(lambda x: \" \".join(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worth single penny works like ton ac provided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bought crompton ozone 75 desert air cooler mon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great packaging seller important point transpo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>delivery delayed days finesafely packedair flo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good cooler crompton height cooler 3ft 10 inch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>good product</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>awsm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>nice product</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150000</th>\n",
       "      <td>fill hot 2 days untill hot soo worth buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147998 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  sentiment\n",
       "0       worth single penny works like ton ac provided ...          1\n",
       "1       bought crompton ozone 75 desert air cooler mon...          1\n",
       "2       great packaging seller important point transpo...          1\n",
       "3       delivery delayed days finesafely packedair flo...          1\n",
       "4       good cooler crompton height cooler 3ft 10 inch...          1\n",
       "...                                                   ...        ...\n",
       "149996                                       good product          1\n",
       "149997                                               awsm          1\n",
       "149998                                       nice product          1\n",
       "149999                                          beautiful          1\n",
       "150000           fill hot 2 days untill hot soo worth buy          1\n",
       "\n",
       "[147998 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removal of HTML Tags: from the reviews\n",
    "df['review'] = df['review'].apply(lambda x:BeautifulSoup(x,'lxml').get_text())\n",
    "\n",
    "#Remove tags and links \n",
    "tag = re.compile(r'<[^>]+>')\n",
    "\n",
    "df['review'] = df['review'].apply(lambda x: tag.sub('', x)) #removing html labels\n",
    "\n",
    "df['review'] = df['review'].replace(r'http\\S+', '', regex=True).replace(r'www.\\S+', '', regex=True).replace(r'http\\S+', '', regex=True).replace(r'\"', '', regex=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of Numbers\n",
    "df['review']=df['review'].apply(lambda x:re.sub(r'[0-9]+','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41842</th>\n",
       "      <td>bad quality</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130252</th>\n",
       "      <td>nice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27676</th>\n",
       "      <td>sound quality fair loud presence noises bass p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49977</th>\n",
       "      <td>superb</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132128</th>\n",
       "      <td>nice product</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111091</th>\n",
       "      <td>buy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32637</th>\n",
       "      <td>excellent voice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23627</th>\n",
       "      <td>nice good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69876</th>\n",
       "      <td>nice product</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51428</th>\n",
       "      <td>goodbat enjoycorona holiday play matches light...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  sentiment\n",
       "41842                                         bad quality          0\n",
       "130252                                               nice          1\n",
       "27676   sound quality fair loud presence noises bass p...          1\n",
       "49977                                              superb          1\n",
       "132128                                       nice product          1\n",
       "111091                                                buy          0\n",
       "32637                                     excellent voice          1\n",
       "23627                                           nice good          1\n",
       "69876                                        nice product          1\n",
       "51428   goodbat enjoycorona holiday play matches light...          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removal of usernames from the reviews\n",
    "df['review']=df['review'].apply(lambda x:re.sub(r'@[A-Za-z0–9]+','',x))\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Abhinav\n",
      "[nltk_data]     Gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worth single penny work like ton ac provide ro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buy crompton ozone desert air cooler month sum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great package seller important point transport...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>delivery delay days finesafely packedair flow ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good cooler crompton height cooler ft inch col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>good product</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>awsm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>nice product</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>beautiful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150000</th>\n",
       "      <td>fill hot days untill hot soo worth buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147998 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  sentiment\n",
       "0       worth single penny work like ton ac provide ro...          1\n",
       "1       buy crompton ozone desert air cooler month sum...          1\n",
       "2       great package seller important point transport...          1\n",
       "3       delivery delay days finesafely packedair flow ...          1\n",
       "4       good cooler crompton height cooler ft inch col...          1\n",
       "...                                                   ...        ...\n",
       "149996                                       good product          1\n",
       "149997                                               awsm          1\n",
       "149998                                       nice product          1\n",
       "149999                                          beautiful          1\n",
       "150000             fill hot days untill hot soo worth buy          1\n",
       "\n",
       "[147998 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization and Lemmanization\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(w, pos=\"v\") for w in w_tokenizer.tokenize(text)])\n",
    "\n",
    "df['review'] = df.review.apply(lemmatize_text).copy()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train:  (110998, 1)\n",
      "Shape of y_train:  (110998, 1)\n",
      "Shape of x_test:   (37000, 1)\n",
      "Shape of y_test:   (37000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Splitting Dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "\n",
    "x = pd.DataFrame(df, columns = ['review']) \n",
    "y = pd.DataFrame(df, columns = ['sentiment']) \n",
    "\n",
    "# Split dataset to train and test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Shape of x_train: \", X_train.shape)\n",
    "print(\"Shape of y_train: \", y_train.shape)\n",
    "print(\"Shape of x_test:  \", X_test.shape)\n",
    "print(\"Shape of y_test:  \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization with TF-IDF ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train shape: (110998, 1000)\n",
      "TF-IDF test shape: (37000, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train = X_train['review'].tolist()\n",
    "test = X_test['review'].tolist()\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, dtype=np.float32)\n",
    "\n",
    "tfidfX_train = tfidf_vectorizer.fit_transform(train)\n",
    "tfidfX_train = tfidfX_train.toarray()\n",
    "\n",
    "tfidfX_test = tfidf_vectorizer.transform(test)\n",
    "tfidfX_test = tfidfX_test.toarray()\n",
    "\n",
    "print(\"TF-IDF train shape:\", tfidfX_train.shape)\n",
    "print(\"TF-IDF test shape:\", tfidfX_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dct = DecisionTreeClassifier(criterion='entropy', random_state=1)\n",
    "dct.fit(tfidfX_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  92.34324324324325\n",
      "Confusion_matrix:\n",
      " [[ 3781  1632]\n",
      " [ 1201 30386]]\n"
     ]
    }
   ],
   "source": [
    "# Making Predictions\n",
    "y_pred_dct = dct.predict(tfidfX_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "\n",
    "dct_accuracy = accuracy_score(y_test,y_pred_dct)*100\n",
    "dct_matrix = confusion_matrix(y_test,y_pred_dct)\n",
    "dct_precision = dct_matrix[0][0]*100/(dct_matrix[0][0]+dct_matrix[1][0])\n",
    "dct_recall = dct_matrix[0][0]*100/(dct_matrix[0][0]+dct_matrix[0][1])\n",
    "\n",
    "print(\"Accuracy : \",dct_accuracy)\n",
    "print(\"Confusion_matrix:\\n\",dct_matrix)\n",
    "# print(\"precision:\",dct_precision)\n",
    "# print(\"recall:\",dct_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boosting ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.9, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=22, ...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xg = XGBClassifier(random_state=22,learning_rate=0.9)\n",
    "xg.fit(tfidfX_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  93.18108108108109\n",
      "Confusion_matrix:\n",
      " [[ 3684  1729]\n",
      " [  794 30793]]\n"
     ]
    }
   ],
   "source": [
    "# Making Predictions\n",
    "y_pred_xg = xg.predict(tfidfX_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "\n",
    "xg_accuracy = accuracy_score(y_test,y_pred_xg)*100\n",
    "xg_matrix = confusion_matrix(y_test,y_pred_xg)\n",
    "xg_precision = xg_matrix[0][0]*100/(xg_matrix[0][0]+xg_matrix[1][0])\n",
    "xg_recall = xg_matrix[0][0]*100/(xg_matrix[0][0]+xg_matrix[0][1])\n",
    "\n",
    "print(\"Accuracy : \",xg_accuracy)\n",
    "print(\"Confusion_matrix:\\n\",xg_matrix)\n",
    "# print(\"precision:\",xg_precision)\n",
    "# print(\"recall:\",xg_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHINA~1\\AppData\\Local\\Temp/ipykernel_18520/2677021949.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf1.fit(tfidfX_train,y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf1 = RandomForestClassifier(n_estimators=150,max_depth=None)\n",
    "rf1.fit(tfidfX_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  93.48378378378378\n",
      "Confusion_matrix:\n",
      " [[ 3729  1684]\n",
      " [  727 30860]]\n"
     ]
    }
   ],
   "source": [
    "# Making Predictions\n",
    "y_pred_rf1 = rf1.predict(tfidfX_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "\n",
    "rf1_accuracy = accuracy_score(y_test,y_pred_rf1)*100\n",
    "rf1_matrix = confusion_matrix(y_test,y_pred_rf1)\n",
    "rf1_precision = rf1_matrix[0][0]*100/(rf1_matrix[0][0]+rf1_matrix[1][0])\n",
    "rf1_recall = rf1_matrix[0][0]*100/(rf1_matrix[0][0]+rf1_matrix[0][1])\n",
    "\n",
    "print(\"Accuracy : \",rf1_accuracy)\n",
    "print(\"Confusion_matrix:\\n\",rf1_matrix)\n",
    "# print(\"precision:\",rf1_precision)\n",
    "# print(\"recall:\",rf1_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Softwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Softwares\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=0,solver='lbfgs')\n",
    "\n",
    "lr.fit(tfidfX_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  92.61351351351351\n",
      "Confusion_matrix:\n",
      " [[ 3383  2030]\n",
      " [  703 30884]]\n"
     ]
    }
   ],
   "source": [
    "# Making Predictions\n",
    "y_pred_lr = lr.predict(tfidfX_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "\n",
    "lr_accuracy = accuracy_score(y_test,y_pred_lr)*100\n",
    "lr_matrix = confusion_matrix(y_test,y_pred_lr)\n",
    "lr_precision = lr_matrix[0][0]*100/(lr_matrix[0][0]+lr_matrix[1][0])\n",
    "lr_recall = lr_matrix[0][0]*100/(lr_matrix[0][0]+lr_matrix[0][1])\n",
    "\n",
    "print(\"Accuracy : \",lr_accuracy)\n",
    "print(\"Confusion_matrix:\\n\",lr_matrix)\n",
    "# print(\"precision:\",lr_precision)\n",
    "# print(\"recall:\",lr_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Tree Classifier ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABHINA~1\\AppData\\Local\\Temp/ipykernel_18520/165346209.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  etc.fit(tfidfX_train,y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(random_state=123)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(random_state=123)\n",
    "etc.fit(tfidfX_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  93.3891891891892\n",
      "Confusion_matrix:\n",
      " [[ 3739  1674]\n",
      " [  772 30815]]\n"
     ]
    }
   ],
   "source": [
    "# Making Predictions\n",
    "y_pred_etc = etc.predict(tfidfX_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "\n",
    "etc_accuracy = accuracy_score(y_test,y_pred_etc)*100\n",
    "etc_matrix = confusion_matrix(y_test,y_pred_etc)\n",
    "etc_precision = etc_matrix[0][0]*100/(etc_matrix[0][0]+etc_matrix[1][0])\n",
    "etc_recall = etc_matrix[0][0]*100/(etc_matrix[0][0]+etc_matrix[0][1])\n",
    "\n",
    "print(\"Accuracy : \",etc_accuracy)\n",
    "print(\"Confusion_matrix:\\n\",etc_matrix)\n",
    "# print(\"precision:\",etc_precision)\n",
    "# print(\"recall:\",etc_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dct', DecisionTreeClassifier(criterion='entropy', random_state=1)),\n",
       " ('xg',\n",
       "  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bynode=None,\n",
       "                colsample_bytree=None, early_stopping_rounds=None,\n",
       "                enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "                gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.9, max_bin=None,\n",
       "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "                predictor=None, random_state=22, ...)),\n",
       " ('rf1', RandomForestClassifier(n_estimators=150)),\n",
       " ('lr', LogisticRegression(random_state=0)),\n",
       " ('etc', ExtraTreesClassifier(random_state=123))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining Estimators\n",
    "\n",
    "estimators = [('dct',dct),('xg',xg),('rf1',rf1),('lr',lr),('etc',etc)]\n",
    "estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Softwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Softwares\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dct',\n",
       "                              DecisionTreeClassifier(criterion='entropy',\n",
       "                                                     random_state=1)),\n",
       "                             ('xg',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=...\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=22, ...)),\n",
       "                             ('rf1', RandomForestClassifier(n_estimators=150)),\n",
       "                             ('lr', LogisticRegression(random_state=0)),\n",
       "                             ('etc', ExtraTreesClassifier(random_state=123))],\n",
       "                 weights=[0.5, 1, 2.5, 1, 2.5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the Estimator\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "vc = VotingClassifier(estimators, weights=[0.5,1,2.5,1,2.5])\n",
    "vc.fit(tfidfX_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  93.53783783783783\n",
      "Confusion_matrix:\n",
      " [[ 3741  1672]\n",
      " [  719 30868]]\n"
     ]
    }
   ],
   "source": [
    "# Making Predictions\n",
    "y_pred_vc = vc.predict(tfidfX_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "\n",
    "vc_accuracy = accuracy_score(y_test,y_pred_vc)*100\n",
    "vc_matrix = confusion_matrix(y_test,y_pred_vc)\n",
    "vc_precision = vc_matrix[0][0]*100/(vc_matrix[0][0]+vc_matrix[1][0])\n",
    "vc_recall = vc_matrix[0][0]*100/(vc_matrix[0][0]+vc_matrix[0][1])\n",
    "\n",
    "print(\"Accuracy : \",vc_accuracy)\n",
    "print(\"Confusion_matrix:\\n\",vc_matrix)\n",
    "# print(\"precision:\",vc_precision)\n",
    "# print(\"recall:\",vc_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>92.343243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XG</th>\n",
       "      <td>93.181081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>93.483784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>92.613514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extra Tree Classifier</th>\n",
       "      <td>93.389189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting Classifier</th>\n",
       "      <td>93.537838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy\n",
       "Decision Tree          92.343243\n",
       "XG                     93.181081\n",
       "Random Forest          93.483784\n",
       "Logistic Regression    92.613514\n",
       "Extra Tree Classifier  93.389189\n",
       "Voting Classifier      93.537838"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Testing Accuracies\")\n",
    "acc_list = {\n",
    "    'Decision Tree':dct_accuracy,\n",
    "    'XG':xg_accuracy,\n",
    "    'Random Forest':rf1_accuracy,\n",
    "    'Logistic Regression':lr_accuracy,\n",
    "    'Extra Tree Classifier':etc_accuracy,\n",
    "    'Voting Classifier':vc_accuracy\n",
    "}\n",
    "acc_df_test = pd.DataFrame.from_dict(acc_list,orient=\"index\",columns=['Accuracy'])\n",
    "acc_df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
